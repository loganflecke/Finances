{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a7c07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CSV Header Names ######\n",
    "## Global Columns, or one that should be normalized to be global, such as date and cost\n",
    "category = 'Category'\n",
    "retailer = 'Description'\n",
    "date = 'Date'\n",
    "cost = 'Amount'\n",
    "\n",
    "## Credit Card CSV Columns\n",
    "transaction_date = 'Transaction Date'\n",
    "transaction_cost = 'Debit'\n",
    "\n",
    "## Bank Account CSV Columns\n",
    "banking_date = \"Date\"\n",
    "banking_cost = \"Amount\"\n",
    "\n",
    "## THESE ARE THE NAMES OF GROCERIES AS THEY APPEAR ON THE TRANSACTIONS CSV FILE\n",
    "grocery_keywords = ['KROGER', 'GIANT', 'SAFEWAY', 'HELLOFRESH', 'WEGMANS', 'FOOD LION']\n",
    "\n",
    "## Names of Sheets to output in the Excel Workbook\n",
    "net_sheet_name = \"Net\"\n",
    "income_sheet_name = \"Income\"\n",
    "expenses_sheet_name = \"Expenses\"\n",
    "analysis_sheet_name = \"Analysis\"\n",
    "\n",
    "###### Mappings and Lookups ######\n",
    "banking_to_income_lookup = {\n",
    "    \"SAFECO\": \"Car Insurance\",\n",
    "    \"PAYMENT AT CAPITAL ONE ONLINE PMT\": \"Credit Card\",\n",
    "    \"PAYMENT AT CAPITAL ONE CRCARDPMT\": \"Credit Card\",\n",
    "    \"PAYMENT AT CAPITAL ONE MOBILE PMT\" : \"Credit Card\",\n",
    "    \"PAYMENT AT CAPITAL ONE TRANSFER\": \"HYSA Transfer\",\n",
    "    \"PAYMENT AT SCHWAB\": \"Investments\",\n",
    "    \"SCHWAB BROKERAGE MONEYLINK\" : \"Investments\",\n",
    "    \"PAYMENT AT GOVERNORS GREEN\": \"Rent\",\n",
    "    \"HUMANA PAYROLL\": \"Payroll\",\n",
    "    \"XAVIER UNIVERSIT PAYROLL\" : \"Payroll\",\n",
    "    \"PLANET FIT CLUB FEES\" : \"Fitness\",\n",
    "    \"COMCAST\": \"Internet\",\n",
    "    \"RECURRING PURCHASE AT SPECTRUM\" : \"Internet\",\n",
    "    \"5/3 ONLINE TRANSFER\" : \"Fifth Third Transfer\",\n",
    "    \"ZELLE PMT\" : \"Zelle\",\n",
    "    \"VENMO\" : \"Venmo\",\n",
    "    \"MOBILE DEPOSIT\" : \"Deposit\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1441b4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spending Tool. Enter start and end date, the location of the CSV transaction files, and if you want an Excel spreadsheet.\n",
      "Ensure all file headers match what is declared in the Python script\n"
     ]
    }
   ],
   "source": [
    "print(\"Spending Tool. Enter start and end date, the location of the CSV transaction files, and if you want an Excel spreadsheet.\")\n",
    "print(\"Ensure all file headers match what is declared in the Python script\")\n",
    "# date_input = input(\"Start date (YYYY-MM-DD): \")\n",
    "date_format = \"%Y-%m-%d\"\n",
    "start_date = pd.to_datetime(\"2025-11-03\")\n",
    "# date_input = input(\"End date (YYYY-MM-DD): \")\n",
    "end_date = pd.to_datetime(\"2025-12-03\")\n",
    "transaction_path = \"../../Finances/Transactions\"\n",
    "banking_path = \"../../Finances/Banking\"\n",
    "budget_tracking_path = \"../../Finances/Official Budget.xlsx\"\n",
    "excel_filename = \"budget.xlsx\"\n",
    "# excel = input(\"Write to Excel Sheet? (Y/N): \")\n",
    "excel=\"Y\"\n",
    "if excel == \"Y\":\n",
    "    excel = True\n",
    "else:\n",
    "    excel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5def2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "global income_df, expenses_df, net_df\n",
    "# # Create a backup of the file at budget_tracking_path\n",
    "# backup_file_path = budget_tracking_path + \".bak\"\n",
    "# print(\"Backup file:\", backup_file_path)\n",
    "# shutil.copy2(budget_tracking_path, backup_file_path)\n",
    "# Read in the file at budget_tracking_path to a series of dataframes\n",
    "expenses_df = pd.read_excel(budget_tracking_path, sheet_name=expenses_sheet_name)\n",
    "income_df = pd.read_excel(budget_tracking_path, sheet_name=income_sheet_name)\n",
    "net_df = pd.DataFrame(columns=['Month', 'Net', 'Income', 'Expenses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27e95de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df_by_date(df, date_field):\n",
    "    df[date_field] = pd.to_datetime(df[date_field])\n",
    "    df = df.sort_values(by=date_field, ascending=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[date_field] = df[date_field].dt.strftime('%Y-%m-%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3567026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_events(input_file_path, dedup_fields):\n",
    "    # Ingest CSV lines\n",
    "    input_events = [os.path.join(input_file_path, f) for f in os.listdir(input_file_path) if os.path.isfile(os.path.join(input_file_path, f))]\n",
    "    input_df = [pd.read_csv(file) for file in input_events]\n",
    "    merged_events = pd.concat(input_df).drop_duplicates(subset=dedup_fields)\n",
    "    # Normalize Date and Amount columns\n",
    "    if banking_date in merged_events.columns and cost in merged_events.columns:\n",
    "        merged_events = merged_events.rename(columns={banking_date: date, cost: cost})\n",
    "    elif transaction_date in merged_events.columns and transaction_cost in merged_events.columns:\n",
    "        merged_events = merged_events.rename(columns={transaction_date: date, transaction_cost: cost})\n",
    "    # Remove $0 events\n",
    "    merged_events = merged_events[merged_events[cost].notna()]\n",
    "    \n",
    "    # Fill in Banking categories\n",
    "    if not category in merged_events.columns:\n",
    "        print(\"Adding categories to merged_banking\")\n",
    "        # Populate the 'category' column in filtered_banking based on retailer\n",
    "        for lookup, category_value in banking_to_income_lookup.items():\n",
    "            merged_events.loc[merged_events[retailer].str.contains(lookup), category] = category_value\n",
    "        # Fill in \"Other\" for events not defined in the lookup\n",
    "        merged_events.loc[merged_events[category].isna(), category] = \"Other\"\n",
    "        merged_events = sort_df_by_date(merged_events, date)\n",
    "    return merged_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cafb3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_events_by_date(start_date, end_date, merged_events):\n",
    "    filtered_events = merged_events[(pd.to_datetime(merged_events.iloc[:, 0]) >= start_date) & \n",
    "                        (pd.to_datetime(merged_events.iloc[:, 0]) <= end_date)].sort_values(by=date, ascending=False) \n",
    "    return filtered_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b4f925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_grocery(merged_transactions):\n",
    "    for keyword in grocery_keywords:\n",
    "        contains_keyword = merged_transactions[retailer].str.contains(keyword, case=False, na=False)\n",
    "        not_fuel = ~merged_transactions[retailer].str.contains('FUEL', case=False, na=False)\n",
    "        if contains_keyword.any() and not_fuel.any():\n",
    "            merged_transactions.loc[contains_keyword & not_fuel, category] = 'Grocery'\n",
    "    return merged_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38c9f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_transaction_categories(filtered_transactions):\n",
    "    transaction_to_expenses_lookup = {\n",
    "        \"Gas/Automotive\" : \"Gas\",\n",
    "        \"Health Care\" : \"Healthcare\",\n",
    "        \"Entertainment\" : \"Other\"\n",
    "    }\n",
    "    for lookup in transaction_to_expenses_lookup:\n",
    "        filtered_transactions.loc[filtered_transactions[category] == lookup, category] = transaction_to_expenses_lookup[lookup]\n",
    "    filtered_transactions.loc[filtered_transactions[category].str.startswith(\"Other\"), category] = \"Other\"            \n",
    "    categories_summary = filtered_transactions.groupby(category)[cost].sum().round(2).reset_index()\n",
    "    return categories_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab8e9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_banking_categories(filtered_banking):\n",
    "    # Now the 'category' column in merged_banking should be filled with the corresponding values\n",
    "    categories_summary = filtered_banking.groupby(category)[banking_cost].sum().round(2).reset_index()\n",
    "    return categories_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98b766cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_totals(filtered_transactions):\n",
    "    date_range_df = pd.DataFrame({date: pd.date_range(start=start_date, end=end_date, freq='D')})\n",
    "    date_range_df[date] = date_range_df[date].dt.date\n",
    "    filtered_transactions[cost] = filtered_transactions[cost].fillna(0)\n",
    "\n",
    "    filtered_transactions['Count'] = 0\n",
    "    date_range_df[cost] = float('nan')\n",
    "    date_range_df['Count'] = 0\n",
    "\n",
    "    for index, row in filtered_transactions.iterrows():\n",
    "        for i, r in date_range_df.iterrows():\n",
    "            if str(row[date]) == str(r[date]):\n",
    "                date_range_df.at[i, 'Count'] += 1\n",
    "                if pd.isna(date_range_df.at[i, cost]):\n",
    "                    date_range_df.at[i, cost] = row[cost]\n",
    "                else:\n",
    "                    date_range_df.at[i, cost] += row[cost]\n",
    "                    date_range_df.at[i, cost] = date_range_df.at[i, cost].round(decimals=2)\n",
    "                break\n",
    "    date_range_df[cost] = date_range_df[cost].fillna(0)   \n",
    "\n",
    "    return date_range_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe71e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_transactions(categories_summary):\n",
    "    global timeline_transactions_df\n",
    "    new_row = {\"Month\": end_date.strftime(\"%Y-%m-%d\")} # One row for new dataframe\n",
    "    timeline_transactions_df.loc[len(timeline_transactions_df)] = new_row # append new row to dataframe\n",
    "    # Set each category cost to its category in the row corresponding to end_month\n",
    "    for index, row in categories_summary.iterrows():\n",
    "        timeline_transactions_df.loc[timeline_transactions_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), row[category]] = row[cost]\n",
    "    timeline_transactions_df = sort_df_by_date(timeline_transactions_df, 'Month')\n",
    "    return timeline_transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b80c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_banking(categorized_banking):\n",
    "    global timeline_banking_df\n",
    "    new_row = {\"Month\": end_date.strftime(\"%Y-%m-%d\")} # One row for new dataframe\n",
    "    timeline_banking_df.loc[len(timeline_banking_df)] = new_row # append new row to dataframe\n",
    "    # Set each category cost to its category in the row corresponding to end_month\n",
    "    for index, row in categorized_banking.iterrows():\n",
    "        timeline_banking_df.loc[timeline_banking_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), row[category]] = row[cost]\n",
    "    timeline_banking_df = sort_df_by_date(timeline_banking_df, 'Month')\n",
    "    return timeline_banking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e73b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_net(filtered_transactions, filtered_banking):\n",
    "    global net_df\n",
    "    transaction_expenses = filtered_transactions[filtered_transactions[cost] > 0] # positive transaction events lose money\n",
    "    banking_expenses = filtered_banking[filtered_banking[cost] < 0] # negative banking events lose money\n",
    "    \n",
    "    transaction_income = filtered_transactions[filtered_transactions[cost] < 0] # negative transaction events gain money\n",
    "    banking_income = filtered_banking[filtered_banking[cost] > 0] # positive banking events gain money\n",
    "            \n",
    "    # Flip the negative to work with positive numbers\n",
    "    transaction_income[cost] = transaction_income[cost].abs()\n",
    "    banking_expenses[cost] = banking_expenses[cost].abs()\n",
    "    \n",
    "    transaction_expenses = transaction_expenses[[date, category, cost]]\n",
    "    banking_expenses = banking_expenses[[date, category, cost]]\n",
    "    transaction_income = transaction_income[[date, category, cost]]\n",
    "    banking_income = banking_income[[date, category, cost]]\n",
    "    \n",
    "    # Keep transactions here to make date of expense/income accurate; don't apply \"Credit Card\" category to expenses\n",
    "    expenses_df = pd.concat(\n",
    "        [\n",
    "            transaction_expenses, \n",
    "            banking_expenses\n",
    "        ])\n",
    "    income_df = pd.concat(\n",
    "        [\n",
    "            transaction_income,\n",
    "            banking_income\n",
    "        ])\n",
    "    \n",
    "    # Exceptions to not count in net\n",
    "    net_exception_categories = [\"HYSA Transfer\", \"Investments\", \"Credit Card\"]\n",
    "    expenses_df = expenses_df[~expenses_df[category].isin(net_exception_categories)]\n",
    "    income_df = income_df[~income_df[category].isin(net_exception_categories)]\n",
    "    \n",
    "    # Append Month totals to Net DF\n",
    "    new_row = {\"Month\": end_date.strftime(\"%Y-%m-%d\")} # One row for new dataframe\n",
    "    net_df.loc[len(net_df)] = new_row # append new row to dataframe\n",
    "    net_df.loc[net_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), \"Income\"] = income_df[cost].sum()\n",
    "    net_df.loc[net_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), \"Expenses\"] = expenses_df[cost].sum()\n",
    "    net_df.loc[net_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), \"Net\"] = (income_df[cost].sum() - expenses_df[cost].sum())\n",
    "    net_df.loc[net_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), \"Difference\"] = ((expenses_df[cost].sum() / income_df[cost].sum())).round(2)\n",
    "    net_df = sort_df_by_date(net_df, 'Month')\n",
    "    return net_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_finances(net_df, timeline_banking_df, timeline_transactions_df):\n",
    "    analysis_df = pd.DataFrame()\n",
    "    return analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eae26ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_excel(dataframe_sheets):\n",
    "    with pd.ExcelWriter(excel_filename) as writer:\n",
    "        keys_list = list(dataframe_sheets.keys())\n",
    "        for sheet in dataframe_sheets:\n",
    "            dataframe_sheets[sheet].to_excel(writer, sheet_name=sheet, index=keys_list.index(sheet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b1bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding categories to merged_banking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:39: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  net_df.loc[net_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), \"Difference\"] = ((expenses_df[cost].sum() / income_df[cost].sum())).round(2)\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:39: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  net_df.loc[net_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), \"Difference\"] = ((expenses_df[cost].sum() / income_df[cost].sum())).round(2)\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:39: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  net_df.loc[net_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), \"Difference\"] = ((expenses_df[cost].sum() / income_df[cost].sum())).round(2)\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:39: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  net_df.loc[net_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), \"Difference\"] = ((expenses_df[cost].sum() / income_df[cost].sum())).round(2)\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:39: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  net_df.loc[net_df['Month'] == end_date.strftime(\"%Y-%m-%d\"), \"Difference\"] = ((expenses_df[cost].sum() / income_df[cost].sum())).round(2)\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_26332/2129509526.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  banking_expenses[cost] = banking_expenses[cost].abs()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file created successfully. budget.xlsx\n"
     ]
    }
   ],
   "source": [
    "merged_transactions = merge_events(transaction_path, [transaction_cost, retailer, transaction_date])\n",
    "merged_banking = merge_events(banking_path, [banking_cost, retailer, banking_date])\n",
    "merged_transactions = enrich_grocery(merged_transactions)\n",
    "\n",
    "timeline_transactions_df = pd.DataFrame(columns=expenses_df.columns)\n",
    "timeline_banking_df = pd.DataFrame(columns=income_df.columns)\n",
    "\n",
    "# For loop to go back X iterations of past Y where past Y was the unit of time to include in this report (likely past month so go back X months, month by month)\n",
    "def iterate_months(iterations):\n",
    "    global end_date, filtered_transactions, timeline_transactions_df, daily_transactions, merged_banking\n",
    "    for i in range(iterations):\n",
    "        # Get time period (length of unit of time minus 1 day)\n",
    "        start_date = end_date - relativedelta(months=1) + relativedelta(days=1) # get latest date and go back as far as the size of the unit (likely a month)\n",
    "        filtered_transactions = filter_events_by_date(start_date, end_date, merged_transactions)\n",
    "        filtered_banking = filter_events_by_date(start_date, end_date, merged_banking)\n",
    "        # daily_transactions = daily_totals(filtered_transactions)\n",
    "        # Expenses\n",
    "        categorized_transactions = summarize_transaction_categories(filtered_transactions)\n",
    "        timeline_transactions_df = append_transactions(categorized_transactions)\n",
    "        # Income\n",
    "        categorized_banking = summarize_banking_categories(filtered_banking)\n",
    "        timeline_banking_df = append_banking(categorized_banking)\n",
    "        # Net\n",
    "        net_df = append_net(filtered_transactions, filtered_banking)\n",
    "        end_date = start_date - relativedelta(days=1)\n",
    "\n",
    "iterate_months(18)\n",
    "analysis_df = analyze_finances(net_df, timeline_banking_df, timeline_transactions_df)\n",
    "\n",
    "dataframe_sheets = {\n",
    "    \"Net\" : net_df,\n",
    "    \"Analysis\" : analysis_df,\n",
    "    \"Transactions\": timeline_transactions_df, \n",
    "    \"Banking\" : timeline_banking_df,\n",
    "    \"All Transactions\" : merged_transactions,\n",
    "    \"All Banking\" : merged_banking\n",
    "}\n",
    "if excel == True:\n",
    "    try:\n",
    "        export_to_excel(dataframe_sheets)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to create Excel file:\", e)\n",
    "    else:\n",
    "        print(\"Excel file created successfully.\", excel_filename)\n",
    "else:\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
