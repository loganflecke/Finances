{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a7c07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5df02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of months to collect, parse, and analyze financial data\n",
    "lookback_months = 8\n",
    "\n",
    "###### CSV Header Names ######\n",
    "## Global Columns, or one that should be normalized to be global, such as date and cost\n",
    "category = 'Category'\n",
    "retailer = 'Description'\n",
    "date = 'Date'\n",
    "cost = 'Amount'\n",
    "\n",
    "## Credit Card CSV Columns\n",
    "transaction_date = 'Transaction Date'\n",
    "transaction_cost = 'Debit'\n",
    "\n",
    "## Bank Account CSV Columns\n",
    "banking_date = \"Date\"\n",
    "banking_cost = \"Amount\"\n",
    "\n",
    "## Capital One 360 Account CSV Columns\n",
    "co_360_date = 'Transaction Date'\n",
    "co_360_retailer = 'Transaction Description'\n",
    "co_360_cost = 'Transaction Amount'\n",
    "co_360_balance = 'Balance'\n",
    "\n",
    "## THESE ARE THE NAMES OF GROCERIES AS THEY APPEAR ON THE TRANSACTIONS CSV FILE\n",
    "grocery_keywords = ['KROGER', 'GIANT', 'SAFEWAY', 'HELLOFRESH', 'WEGMANS', 'FOOD LION']\n",
    "\n",
    "###### Mappings and Lookups ######\n",
    "banking_to_income_lookup = {\n",
    "    \"SAFECO\": \"Car Insurance\",\n",
    "    \"PAYMENT AT CAPITAL ONE ONLINE PMT\": \"Credit Card\",\n",
    "    \"PAYMENT AT CAPITAL ONE CRCARDPMT\": \"Credit Card\",\n",
    "    \"PAYMENT AT CAPITAL ONE MOBILE PMT\" : \"Credit Card\",\n",
    "    \"Preauthorized Deposit from FIFTH THIRD BANK\" : \"HYSA Transfer\",\n",
    "    \"PAYMENT AT CAPITAL ONE TRANSFER\": \"HYSA Transfer\",\n",
    "    \"PAYMENT AT SCHWAB\": \"Investments\",\n",
    "    \"SCHWAB BROKERAGE MONEYLINK\" : \"Investments\",\n",
    "    \"PAYMENT AT GOVERNORS GREEN\": \"Rent\",\n",
    "    \"HUMANA PAYROLL\": \"Payroll\",\n",
    "    \"XAVIER UNIVERSIT PAYROLL\" : \"Payroll\",\n",
    "    \"PLANET FIT CLUB FEES\" : \"Fitness\",\n",
    "    \"COMCAST\": \"Internet\",\n",
    "    \"RECURRING PURCHASE AT SPECTRUM\" : \"Internet\",\n",
    "    \"5/3 ONLINE TRANSFER\" : \"Fifth Third Transfer\",\n",
    "    \"ZELLE PMT\" : \"Zelle\",\n",
    "    \"VENMO\" : \"Venmo\",\n",
    "    \"MOBILE DEPOSIT\" : \"Deposit\"\n",
    "}\n",
    "transaction_to_expenses_lookup = {\n",
    "    \"Gas/Automotive\" : \"Gas\",\n",
    "    \"Health Care\" : \"Healthcare\",\n",
    "    \"Entertainment\" : \"Other\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1441b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = \"%Y-%m-%d\"\n",
    "transaction_path = \"./Transactions\"\n",
    "banking_path = \"./Banking\"\n",
    "coc_path = \"./COC\"\n",
    "hysa_path = \"./HYSA\"\n",
    "excel_filename = \"budget.xlsx\"\n",
    "excel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18dc10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    merged_transactions = merge_events(input_file_path=transaction_path)\n",
    "    merged_banking = merge_events(banking_path)\n",
    "    merged_coc = merge_events(coc_path)\n",
    "    merged_hysa = merge_events(hysa_path)\n",
    "    merged_transactions = enrich_grocery(merged_transactions)\n",
    "\n",
    "    merged_event_dfs = {\n",
    "        \"transactions\" : merged_transactions, \n",
    "        \"banking\" : merged_banking, \n",
    "        \"coc\" : merged_coc, \n",
    "        \"hysa\" : merged_hysa\n",
    "    }\n",
    "\n",
    "    net_df = iterate_months(merged_event_dfs, lookback_months)\n",
    "\n",
    "    dataframe_sheets = {\n",
    "        \"Net\" : net_df,\n",
    "        \"All Transactions\" : merged_transactions,\n",
    "        \"All Banking\" : merged_banking,\n",
    "        \"All Cap One Checking\" : merged_coc,\n",
    "        \"All HYSA\" : merged_hysa\n",
    "    }\n",
    "    if excel == True:\n",
    "        try:\n",
    "            export_to_excel(dataframe_sheets)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create Excel file:\", e)\n",
    "        else:\n",
    "            print(\"Excel file created successfully.\", excel_filename)\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5c09ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MonthlyModel:\n",
    "    month: str\n",
    "    income: float\n",
    "    expenses: float\n",
    "    fixed_expenses: float\n",
    "    variable_expenses: float\n",
    "    discretionary_expenses: float\n",
    "    investments: float\n",
    "    hy_savings: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27e95de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df_by_date(df, date_field):\n",
    "    df[date_field] = pd.to_datetime(df[date_field])\n",
    "    df = df.sort_values(by=date_field, ascending=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[date_field] = df[date_field].dt.strftime('%Y-%m-%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3567026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_events(input_file_path):\n",
    "    # Ingest CSV lines\n",
    "    input_events = [os.path.join(input_file_path, f) for f in os.listdir(input_file_path) if os.path.isfile(os.path.join(input_file_path, f))]\n",
    "    input_df = [pd.read_csv(file) for file in input_events]\n",
    "    merged_events = pd.concat(input_df)\n",
    "    # Normalize column names\n",
    "    column_field_mapping = {\n",
    "        cost : [banking_cost, transaction_cost, co_360_cost],\n",
    "        retailer : [co_360_retailer],\n",
    "        date : [banking_date, transaction_date, co_360_date]\n",
    "    }\n",
    "    for col in column_field_mapping:\n",
    "        for field in column_field_mapping[col]:\n",
    "            if field in merged_events.columns:\n",
    "                merged_events = merged_events.rename(columns={field: col})\n",
    "                break\n",
    "    # Dedup\n",
    "    merged_events = merged_events.drop_duplicates(subset=[cost, retailer, date])\n",
    "    # Remove $0 events\n",
    "    merged_events = merged_events[merged_events[cost].notna()]\n",
    "    \n",
    "    # Fill in categories\n",
    "    if not category in merged_events.columns:\n",
    "        # Fill in category for Capital One\n",
    "        if \"COC\" in input_file_path or \"HYSA\" in input_file_path:\n",
    "            merged_events[category] = str(input_file_path).replace(\"./\", \"\")\n",
    "        # Populate the 'category' column based on retailer\n",
    "        for lookup, category_value in banking_to_income_lookup.items():\n",
    "            merged_events.loc[merged_events[retailer].str.contains(lookup), category] = category_value\n",
    "        # Fill in \"Other\" for events not defined in the lookup\n",
    "        merged_events.loc[merged_events[category].isna(), category] = \"Other\"\n",
    "        merged_events = sort_df_by_date(merged_events, date)\n",
    "    return merged_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cafb3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_events_by_date(start_date, end_date, merged_events):\n",
    "    filtered_events = merged_events[(pd.to_datetime(merged_events[date], format=date_format) >= start_date) & \n",
    "                        (pd.to_datetime(merged_events[date], format=date_format) <= end_date)].sort_values(by=date, ascending=False) \n",
    "    return filtered_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b4f925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_grocery(merged_transactions):\n",
    "    for keyword in grocery_keywords:\n",
    "        contains_keyword = merged_transactions[retailer].str.contains(keyword, case=False, na=False)\n",
    "        not_fuel = ~merged_transactions[retailer].str.contains('FUEL', case=False, na=False)\n",
    "        if contains_keyword.any() and not_fuel.any():\n",
    "            merged_transactions.loc[contains_keyword & not_fuel, category] = 'Grocery'\n",
    "    return merged_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "08515978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cash_flow(dfs, negate_cost_for=None):\n",
    "    frames = []\n",
    "    for name, df in dfs.items():\n",
    "        if name in negate_cost_for:\n",
    "            df = df.assign(**{cost: -df[cost]})\n",
    "        frames.append(df[[date, retailer, category, cost]])\n",
    "\n",
    "    return pd.concat(frames, ignore_index=True).sort_values(by=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a30c4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cash_flow(event_dfs: pd.DataFrame):\n",
    "    exception_categories = [\"HYSA Transfer\", \"Investments\", \"Credit Card\"]\n",
    "    event_dfs = event_dfs[~event_dfs[category].isin(exception_categories)]\n",
    "    income_df, expenses_df = pd.DataFrame(), pd.DataFrame()\n",
    "    income_df = event_dfs[event_dfs[cost] > 0]\n",
    "    expenses_df = event_dfs[event_dfs[cost] < 0]\n",
    "    return income_df, expenses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28e31748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_expenses(expenses_df):\n",
    "    # Rent, insurance, internet\n",
    "    fixed_expenses_df = expenses_df[expenses_df[category].isin([\"Rent\", \"Car Insurance\", \"Health Care\", \"Internet\"])]\n",
    "    # Groceries, gas, vet\n",
    "    variable_expenses_df = expenses_df[expenses_df[category].isin([\"Gas/Automotive\", \"Grocery\", \"Professional Services\"])]\n",
    "    # Dining, coffee, entertainment\n",
    "    discretionary_expenses_df = expenses_df[\n",
    "        ~expenses_df[category].isin(fixed_expenses_df[category].unique())\n",
    "        & ~expenses_df[category].isin(variable_expenses_df[category].unique())]\n",
    "    return fixed_expenses_df, variable_expenses_df, discretionary_expenses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "caead77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cashflow_model(month_start, master_events_df, income_df, expenses_df):\n",
    "    fixed_expenses_df, variable_expenses_df, discretionary_expenses_df = define_expenses(expenses_df)\n",
    "    return MonthlyModel(\n",
    "        month = month_start,\n",
    "        income = income_df[cost].sum(),\n",
    "        expenses = expenses_df[cost].sum(),\n",
    "        fixed_expenses = fixed_expenses_df[cost].sum(),\n",
    "        variable_expenses = variable_expenses_df[cost].sum(),\n",
    "        discretionary_expenses = discretionary_expenses_df[cost].sum(),\n",
    "        investments = abs(master_events_df.loc[master_events_df[category] == \"Investments\", cost].sum()),\n",
    "        hy_savings = master_events_df.loc[master_events_df[category] == \"HYSA\", cost].sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "023fc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(merged_event_dfs, month_start, month_end):\n",
    "    # Get time period (length of unit of time minus 1 day)\n",
    "    filtered_transactions = filter_events_by_date(month_start, month_end, merged_event_dfs[\"transactions\"])\n",
    "    filtered_banking = filter_events_by_date(month_start, month_end, merged_event_dfs[\"banking\"])\n",
    "    filtered_coc = filter_events_by_date(month_start, month_end, merged_event_dfs[\"coc\"])\n",
    "    filtered_hysa = filter_events_by_date(month_start, month_end, merged_event_dfs[\"hysa\"])\n",
    "\n",
    "    master_events_df = merge_cash_flow(\n",
    "        {\n",
    "            \"transactions\": filtered_transactions,\n",
    "            \"banking\": filtered_banking,\n",
    "            \"coc\": filtered_coc,\n",
    "            \"hysa\": filtered_hysa,\n",
    "        },\n",
    "        negate_cost_for={\"transactions\"}\n",
    "    )\n",
    "    income_df, expenses_df = get_cash_flow(master_events_df)\n",
    "    return build_cashflow_model(month_start, master_events_df, income_df, expenses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76a23307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_months(merged_event_dfs, months_back: int):\n",
    "    states = []\n",
    "\n",
    "    today = datetime.date.today()\n",
    "    current_month_start = today.replace(day=1)\n",
    "\n",
    "    for i in range(months_back):\n",
    "        # shift month back by i\n",
    "        year = current_month_start.year\n",
    "        month = current_month_start.month - i\n",
    "\n",
    "        while month <= 0:\n",
    "            month += 12\n",
    "            year -= 1\n",
    "\n",
    "        month_start = datetime.date(year, month, 1)\n",
    "\n",
    "        # compute month end\n",
    "        next_month = month_start.replace(day=28) + datetime.timedelta(days=4)\n",
    "        month_end = next_month - datetime.timedelta(days=next_month.day)\n",
    "\n",
    "        states.append(\n",
    "            get_state(\n",
    "                merged_event_dfs,\n",
    "                pd.to_datetime(month_start),\n",
    "                pd.to_datetime(month_end),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    state_df = pd.DataFrame(states)\n",
    "    state_df.columns = (col.title() for col in state_df.columns)\n",
    "    return sort_df_by_date(state_df, \"Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8d289e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurring_expenses(expenses_df):\n",
    "    recurring_expenses_df = pd.DataFrame()\n",
    "    return recurring_expenses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eae26ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_excel(dataframe_sheets):\n",
    "    with pd.ExcelWriter(excel_filename) as writer:\n",
    "        keys_list = list(dataframe_sheets.keys())\n",
    "        for sheet in dataframe_sheets:\n",
    "            dataframe_sheets[sheet].to_excel(writer, sheet_name=sheet, index=keys_list.index(sheet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50d893bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_23517/3951328970.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[date_field] = pd.to_datetime(df[date_field])\n",
      "/var/folders/yc/17jq1fyj4n305rbtcn_vxw480000gn/T/ipykernel_23517/3951328970.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[date_field] = pd.to_datetime(df[date_field])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file created successfully. budget.xlsx\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
