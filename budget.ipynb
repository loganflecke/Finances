{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7c07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "import merchant_intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1441b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = \"%Y-%m-%d\"\n",
    "local_merch_intel_filename=\"local_merch_intel.csv\"\n",
    "local_category_mapping_filename = \"local_category_mapping.json\"\n",
    "transaction_path = \"./Transactions\"\n",
    "banking_path = \"./Banking\"\n",
    "coc_path = \"./COC\"\n",
    "hysa_path = \"./HYSA\"\n",
    "excel_filename = \"budget.xlsx\"\n",
    "excel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5df02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of months to collect, parse, and analyze financial data\n",
    "lookback_months = 8\n",
    "\n",
    "###### CSV Header Names ######\n",
    "## Global Columns, or one that should be normalized to be global, such as date and cost\n",
    "category = 'Category'\n",
    "description = 'Description'\n",
    "date = 'Date'\n",
    "cost = 'Amount'\n",
    "\n",
    "## Credit Card CSV Columns\n",
    "transaction_date = 'Transaction Date'\n",
    "transaction_cost = 'Debit'\n",
    "\n",
    "## Bank Account CSV Columns\n",
    "banking_date = \"Date\"\n",
    "banking_cost = \"Amount\"\n",
    "\n",
    "## Capital One 360 Account CSV Columns\n",
    "co_360_date = 'Transaction Date'\n",
    "co_360_retailer = 'Transaction Description'\n",
    "co_360_cost = 'Transaction Amount'\n",
    "co_360_balance = 'Balance'\n",
    "\n",
    "## THESE ARE THE NAMES OF GROCERIES AS THEY APPEAR ON THE TRANSACTIONS CSV FILE\n",
    "grocery_keywords = ['KROGER', 'GIANT', 'SAFEWAY', 'HELLOFRESH', 'WEGMANS', 'FOOD LION']\n",
    "\n",
    "###### Mappings and Lookups ######\n",
    "with open(local_category_mapping_filename, 'r') as file:\n",
    "    local_category_mapping = json.load(file)\n",
    "\n",
    "transaction_to_expenses_lookup = {\n",
    "    \"Gas/Automotive\" : \"Gas\",\n",
    "    \"Health Care\" : \"Healthcare\",\n",
    "    \"Entertainment\" : \"Other\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c09ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MonthlyModel:\n",
    "    month: str\n",
    "    net: str\n",
    "    income: float\n",
    "    expenses: float\n",
    "    fixed_expenses: float\n",
    "    variable_expenses: float\n",
    "    discretionary_expenses: float\n",
    "    investments: float\n",
    "    hy_savings: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e95de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df_by_date(df, date_field):\n",
    "    df[date_field] = pd.to_datetime(df[date_field], format='mixed')\n",
    "    df = df.sort_values(by=date_field, ascending=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[date_field] = df[date_field].dt.strftime('%Y-%m-%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3567026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_events(input_file_path):\n",
    "    # Ingest CSV lines\n",
    "    input_events = [os.path.join(input_file_path, f) for f in os.listdir(input_file_path) if os.path.isfile(os.path.join(input_file_path, f))]\n",
    "    input_df = [pd.read_csv(file) for file in input_events]\n",
    "    merged_events = pd.concat(input_df)\n",
    "    # Normalize column names\n",
    "    column_field_mapping = {\n",
    "        cost : [banking_cost, transaction_cost, co_360_cost],\n",
    "        description : [co_360_retailer],\n",
    "        date : [banking_date, transaction_date, co_360_date]\n",
    "    }\n",
    "    for col in column_field_mapping:\n",
    "        for field in column_field_mapping[col]:\n",
    "            if field in merged_events.columns:\n",
    "                merged_events = merged_events.rename(columns={field: col})\n",
    "                break\n",
    "    # Dedup\n",
    "    merged_events = merged_events.drop_duplicates(subset=[cost, description, date])\n",
    "    # Remove $0 events\n",
    "    merged_events = merged_events[merged_events[cost].notna()]\n",
    "    \n",
    "    # Fill in categories\n",
    "    if not category in merged_events.columns:\n",
    "        # Fill in category for Capital One\n",
    "        if \"COC\" in input_file_path or \"HYSA\" in input_file_path:\n",
    "            merged_events[category] = str(input_file_path).replace(\"./\", \"\")\n",
    "        # Populate the 'category' column based on description\n",
    "        for category_value, descriptions in local_category_mapping.items():\n",
    "            merged_events.loc[merged_events[description].str.contains(description for description in descriptions), category] = category_value\n",
    "        # Fill in \"Other\" for events not defined in the lookup\n",
    "        merged_events.loc[merged_events[category].isna(), category] = \"Other\"\n",
    "        merged_events = sort_df_by_date(merged_events, date)\n",
    "    return merged_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cafb3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_events_by_date(start_date, end_date, merged_events):\n",
    "    filtered_events = merged_events[(pd.to_datetime(merged_events[date], format=date_format) >= start_date) & \n",
    "                        (pd.to_datetime(merged_events[date], format=date_format) <= end_date)].sort_values(by=date, ascending=False) \n",
    "    return filtered_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b4f925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_grocery(merged_transactions):\n",
    "    for keyword in grocery_keywords:\n",
    "        contains_keyword = merged_transactions[description].str.contains(keyword, case=False, na=False)\n",
    "        not_fuel = ~merged_transactions[description].str.contains('FUEL', case=False, na=False)\n",
    "        if contains_keyword.any() and not_fuel.any():\n",
    "            merged_transactions.loc[contains_keyword & not_fuel, category] = 'Grocery'\n",
    "    return merged_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08515978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns normalized event df of all events\n",
    "# Input a dict of dfs (key: df name; value: df; negate_cost_for={df name} for dfs where expenses are positive) \n",
    "def merge_cash_flow(dfs, negate_cost_for=None):\n",
    "    frames = []\n",
    "    for name, df in dfs.items():\n",
    "        if name in negate_cost_for:\n",
    "            df = df.assign(**{cost: -df[cost]})\n",
    "        frames.append(df[[date, description, category, cost]])\n",
    "\n",
    "    return pd.concat(frames, ignore_index=True).sort_values(by=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return income and expense dfs\n",
    "# Input a df of merged events\n",
    "def get_cash_flow(event_dfs: pd.DataFrame):\n",
    "    exception_categories = [\"HYSA Transfer\", \"Investments\", \"Credit Card\"]\n",
    "    event_dfs = event_dfs[~event_dfs[category].isin(exception_categories)]\n",
    "    income_df, expenses_df = pd.DataFrame(), pd.DataFrame()\n",
    "    income_df = event_dfs[event_dfs[cost] > 0]\n",
    "    expenses_df = event_dfs[event_dfs[cost] < 0]\n",
    "    expenses_df.loc[:, cost] = expenses_df.loc[:, cost].abs()\n",
    "    return income_df, expenses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e31748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return fixed, variable, and discretionary expenses from an expenses df\n",
    "# Input expenses df\n",
    "def define_expenses(expenses_df):\n",
    "    # Rent, insurance, internet\n",
    "    fixed_expenses_df = expenses_df[expenses_df[category].isin([\"Rent\", \"Car Insurance\", \"Health Care\", \"Internet\"])]\n",
    "    # Groceries, gas, vet\n",
    "    variable_expenses_df = expenses_df[expenses_df[category].isin([\"Gas/Automotive\", \"Grocery\", \"Professional Services\"])]\n",
    "    # Dining, coffee, entertainment\n",
    "    discretionary_expenses_df = expenses_df[\n",
    "        ~expenses_df[category].isin(fixed_expenses_df[category].unique())\n",
    "        & ~expenses_df[category].isin(variable_expenses_df[category].unique())]\n",
    "    return fixed_expenses_df, variable_expenses_df, discretionary_expenses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caead77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the MonthlyModel dataclass\n",
    "def build_cashflow_model(month_start, master_events_df, income_df, expenses_df):\n",
    "    fixed_expenses_df, variable_expenses_df, discretionary_expenses_df = define_expenses(expenses_df)\n",
    "    return MonthlyModel(\n",
    "        month = month_start,\n",
    "        net = income_df[cost].sum() - expenses_df[cost].sum(),\n",
    "        income = income_df[cost].sum(),\n",
    "        expenses = expenses_df[cost].sum(),\n",
    "        fixed_expenses = fixed_expenses_df[cost].sum(),\n",
    "        variable_expenses = variable_expenses_df[cost].sum(),\n",
    "        discretionary_expenses = discretionary_expenses_df[cost].sum(),\n",
    "        investments = abs(master_events_df.loc[master_events_df[category] == \"Investments\", cost].sum()),\n",
    "        hy_savings = master_events_df.loc[master_events_df[category] == \"HYSA\", cost].sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023fc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the data processing and analysis for a dict event dfs (key: df name; value: df)\n",
    "# Returns the monthly model\n",
    "# Input a dict of dfs (key: df name; value: df)\n",
    "def get_state(merged_event_dfs, month_start, month_end):\n",
    "    # Get time period (length of unit of time minus 1 day)\n",
    "    filtered_transactions = filter_events_by_date(month_start, month_end, merged_event_dfs[\"transactions\"])\n",
    "    filtered_banking = filter_events_by_date(month_start, month_end, merged_event_dfs[\"banking\"])\n",
    "    filtered_coc = filter_events_by_date(month_start, month_end, merged_event_dfs[\"coc\"])\n",
    "    filtered_hysa = filter_events_by_date(month_start, month_end, merged_event_dfs[\"hysa\"])\n",
    "\n",
    "    master_events_df = merge_cash_flow(\n",
    "        {\n",
    "            \"transactions\": filtered_transactions,\n",
    "            \"banking\": filtered_banking,\n",
    "            \"coc\": filtered_coc,\n",
    "            \"hysa\": filtered_hysa,\n",
    "        },\n",
    "        negate_cost_for={\"transactions\"}\n",
    "    )\n",
    "    income_df, expenses_df = get_cash_flow(master_events_df)\n",
    "    return build_cashflow_model(month_start, master_events_df, income_df, expenses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a23307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a df of X number of monthly models, one per row\n",
    "# Input a dict of dfs (key: df name; value: df)\n",
    "def iterate_months(merged_event_dfs, months_back: int):\n",
    "    states = []\n",
    "\n",
    "    today = datetime.date.today()\n",
    "    current_month_start = today.replace(day=1)\n",
    "\n",
    "    for i in range(months_back):\n",
    "        # shift month back by i\n",
    "        year = current_month_start.year\n",
    "        month = current_month_start.month - i\n",
    "\n",
    "        while month <= 0:\n",
    "            month += 12\n",
    "            year -= 1\n",
    "\n",
    "        month_start = datetime.date(year, month, 1)\n",
    "\n",
    "        # compute month end\n",
    "        next_month = month_start.replace(day=28) + datetime.timedelta(days=4)\n",
    "        month_end = next_month - datetime.timedelta(days=next_month.day)\n",
    "\n",
    "        states.append(\n",
    "            get_state(\n",
    "                merged_event_dfs,\n",
    "                pd.to_datetime(month_start),\n",
    "                pd.to_datetime(month_end),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    state_df = pd.DataFrame(states)\n",
    "    state_df.columns = (col.title() for col in state_df.columns)\n",
    "    return sort_df_by_date(state_df, \"Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae26ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_excel(dataframe_sheets):\n",
    "    with pd.ExcelWriter(excel_filename) as writer:\n",
    "        keys_list = list(dataframe_sheets.keys())\n",
    "        for sheet in dataframe_sheets:\n",
    "            dataframe_sheets[sheet].to_excel(writer, sheet_name=sheet, index=keys_list.index(sheet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18dc10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    merged_transactions = merge_events(transaction_path)\n",
    "    merged_banking = merge_events(banking_path)\n",
    "    merged_coc = merge_events(coc_path)\n",
    "    merged_hysa = merge_events(hysa_path)\n",
    "    merged_transactions = enrich_grocery(merged_transactions)\n",
    "\n",
    "    merged_event_dfs = {\n",
    "        \"transactions\" : merged_transactions, \n",
    "        \"banking\" : merged_banking, \n",
    "        \"coc\" : merged_coc, \n",
    "        \"hysa\" : merged_hysa\n",
    "    }\n",
    "\n",
    "    net_df = iterate_months(merged_event_dfs, lookback_months)\n",
    "    \n",
    "    merged_all = merge_cash_flow(\n",
    "        {\n",
    "            \"transactions\": merged_transactions,\n",
    "            \"banking\": merged_banking,\n",
    "            \"coc\": merged_coc,\n",
    "            \"hysa\": merged_hysa,\n",
    "        },\n",
    "        negate_cost_for={\"transactions\"}\n",
    "    )\n",
    "    \n",
    "    income_df, expenses_df = get_cash_flow(merged_all)\n",
    "    fixed_expenses_df, variable_expenses_df, discretionary_expenses_df = define_expenses(expenses_df)\n",
    "\n",
    "    dataframe_sheets = {\n",
    "        \"Net\" : net_df,\n",
    "        \"Fixed Expenses\" : fixed_expenses_df,\n",
    "        \"Variable Expenses\" : variable_expenses_df,\n",
    "        \"Discretionary Expenses\" : discretionary_expenses_df,\n",
    "        \"All Transactions\" : merged_transactions,\n",
    "        \"All Banking\" : merged_banking,\n",
    "        \"All Cap One Checking\" : merged_coc,\n",
    "        \"All HYSA\" : merged_hysa\n",
    "    }\n",
    "    if excel == True:\n",
    "        try:\n",
    "            export_to_excel(dataframe_sheets)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create Excel file:\", e)\n",
    "        else:\n",
    "            print(\"Excel file created successfully.\", excel_filename)\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50d893bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8d289e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_expenses(expenses_df):\n",
    "    value_counts = expenses_df[description].value_counts()\n",
    "    expenses_df[date] = pd.to_datetime(expenses_df[date])\n",
    "    cutoff_date = datetime.datetime.now() - pd.DateOffset(months=lookback_months)\n",
    "    expenses_df.loc[:, 'frequency'] = expenses_df[description].map(value_counts).astype(int)\n",
    "    recent_frequented_merchants = expenses_df.loc[(expenses_df['frequency'] > 1) & (expenses_df[date] >= cutoff_date), description].drop_duplicates(ignore_index=True)\n",
    "    return recent_frequented_merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1df361cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_transactions = merge_events(transaction_path)\n",
    "merged_banking = merge_events(banking_path)\n",
    "merged_coc = merge_events(coc_path)\n",
    "merged_hysa = merge_events(hysa_path)\n",
    "merged_transactions = enrich_grocery(merged_transactions)\n",
    "\n",
    "merged_all = merge_cash_flow(\n",
    "    {\n",
    "        \"transactions\": merged_transactions,\n",
    "        \"banking\": merged_banking,\n",
    "        \"coc\": merged_coc,\n",
    "        \"hysa\": merged_hysa,\n",
    "    },\n",
    "    negate_cost_for={\"transactions\"}\n",
    ")\n",
    "\n",
    "income_df, expenses_df = get_cash_flow(merged_all)\n",
    "recent_frequented_merchants = get_frequent_expenses(expenses_df)\n",
    "merchant_intelligence.build_merchant_intel(recent_frequented_merchants, local_merch_intel_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
